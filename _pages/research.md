---
layout: archive
title: "Research"
permalink: /research_2/
author_profile: true
---

## Job Market Paper

----------------------------------------------------------------


## Submitted for Publication

----------------------------------------------------------------
<!-- ### _**Kernel Three Pass Regression Filter**_ <br> -->
<!-- <span style="font-size:15px"> (with Daanish Padha) ()</span> -->
### **Kernel Three Pass Regression Filter** <br>
(with Daanish Padha) (Manuscript)
<a href="https://github.com/rajveerjat/rajveerjat.github.io/blob/master/files/Kernel_3PRF.pdf" target="_blank" rel="noopener noreferrer" style="color: black; font-weight:bold; text-decoration: underline;">
 Kernel Three Pass Regression Filter</a> <br>
\[Accepted for Presentation in The 2024 California Econometrics Conference \] <br>
\[Accepted for Presentation in the 34th annual Midwest Econometrics Group Conference \]

<details>
<summary>Abstract</summary>
<br>
We forecast a single time series using a high-dimensional set of predictors. When predictors share common underlying dynamics, a latent factor model estimated by the Principal Component method effectively characterizes their co-movements. These latent factors succinctly summarize the data and aid in prediction, mitigating the curse of dimensionality. However, two significant drawbacks arise: (1) not all factors may be relevant, and utilizing all of them in constructing forecasts leads to inefficiency, and (2) typical models assume a linear dependence of the target on the set of predictors, which limits accuracy. We address these issues through a novel method: Kernel Three-Pass Regression Filter. This method extends a supervised forecasting technique, the Three-Pass Regression Filter, to exclude irrelevant information and operate within an enhanced framework capable of handling nonlinear dependencies. Our method is computationally efficient and demonstrates strong empirical performance, particularly over longer forecast horizons.
</details>



## Work In Progress
----------------------------------------------------------------

<br>
<!-- ### _**[Supervised Deep Dynamic Factor Models for Forecasting]**_   -->
(with [Daanish Padha] <br>
<details>
<summary>Abstract</summary>
<br>
We forecast a single time series using a high-dimensional set of predictors. When these predictors share common underlying dynamics, an approximate latent factor model provides a powerful characterization of their co-movements \cite{bai2003}. These latent factors succinctly summarize the data and can also be used for prediction, alleviating the curse of dimensionality in high-dimensional prediction exercises, see \cite{sw}. However, forecasting using these latent factors suffers from two potential drawbacks. First, not all-pervasive factors among the set of predictors may be relevant, and using all of them can lead to inefficient forecasts. The second shortcoming is the assumption of linear dependence of predictors on the underlying factors. The first issue can be addressed by using some form of supervision, which leads to omitting irrelevant information. The second issue can alleviated by allowing non-linear dependence of predictors on factors. We use supervised deep dynamic factor models to learn the non-linear latent factor structure in the data. We compare the forecasting performance of our method against the competing approaches in the literature.

</details>


